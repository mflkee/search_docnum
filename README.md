![1](https://github.com/mflkee/search_docnum/blob/main/docs/screenshot-2025-10-16_16-26-42.png)
![2](https://github.com/mflkee/search_docnum/blob/main/docs/screenshot-2025-10-16_16-26-20.png)


Эта система автоматизирует поиск актуальных сведений о поверке средств измерений (СИ) в ФГИС «Аршин», обновляет локальные данные и формирует отчётность. Проект реализован на асинхронном стеке FastAPI + httpx + pandas, конфигурация управляется через `.env`, а логирование ведётся в `logs/app_YYYYMMDD.log`.

## Основные возможности
- Загрузка исходного Excel (`input.xlsx`) с произвольными названиями колонок для даты поверки и номера свидетельства.
- Валидация структуры файла и автоматический выбор нужного листа (по умолчанию «Перечень»).
- Двухэтапный поиск записей в ФГИС «Аршин» с учётом ограничений по частоте запросов и повторными попытками при сбоях.
- Учёт даты окончания поверки из исходного файла для поиска актуальной записи и обработка сдвига по годам (например, для просроченных поверок).
- Параллельная обработка записей с распределением нагрузки и соблюдением лимитов Аршина.
- Обновление локальных записей актуальными сведениями (ID в Аршине, тип СИ, организация-поверитель и т.д.) с фиксацией изменений номера свидетельства.
- Формирование отчёта `output.xlsx`, сводной статистики и логирование пропущенных строк с некорректными данными.
- Интерактивный предпросмотр обработанных данных с сортировкой, фильтрами и вычисляемыми интервалами поверок.

## Требования
- Python 3.13
- [uv](https://docs.astral.sh/uv/latest/) ≥ 0.4
- Docker 24+ и Docker Compose 2.20+ (для контейнерного запуска)

## Конфигурация
Все настройки задаются через переменные окружения и загружаются при помощи `pydantic-settings`. Создайте файл `.env` в корне проекта и задайте как минимум:

```
ARSHIN_API_BASE_URL=https://fgis.gost.ru/fundmetrology/eapi
ARSHIN_API_RATE_LIMIT=60
ARSHIN_API_RATE_PERIOD=60
ARSHIN_MAX_CONCURRENT_REQUESTS=10
UPLOAD_DIR=uploads
RESULTS_DIR=results
LOGURU_ENQUEUE=auto
```

Дополнительные параметры и их значения по умолчанию смотрите в `src/config/settings.py`.

## Локальный запуск (uv)
1. Установите зависимости:
   ```bash
   uv sync
   ```
2. Запустите API:
   ```bash
   uv run uvicorn src.api.main:app --host 0.0.0.0 --port 8000 --reload
   ```
3. Перейдите в браузере на `http://localhost:8000` для использования веб-интерфейса загрузки файла или работайте через REST API.

## Тестирование
```bash
uv run pytest --maxfail=1 --disable-warnings
```

Для измерения покрытия:
```bash
uv run pytest --cov=src --cov-report=term-missing
```

## Контейнеризация
1. Соберите образ:
   ```bash
   docker compose -f docker/docker-compose.yml build
   ```
2. Запустите сервисы (API + Redis):
   ```bash
   docker compose -f docker/docker-compose.yml up
   ```
3. API будет доступен по адресу `http://localhost:8000`. Логи, результаты обработки и загруженные файлы монтируются в локальные директории `./logs`, `./results`, `./uploads`.

## Основные конечные точки API
| Метод | URL                    | Описание                                           |
|-------|------------------------|----------------------------------------------------|
| GET   | `/api/v1/health`       | Health-check сервиса                               |
| POST  | `/api/v1/upload`       | Загрузка Excel-файла для обработки (форм-data)     |
| GET   | `/api/v1/status/{id}`  | Текущее состояние задачи                           |
| GET   | `/api/v1/results/{id}` | Скачивание готового отчёта                         |
| GET   | `/api/task-status/{id}`| Статус задачи для SPA/UI (JSON)                    |

Пример запроса на загрузку файла:
```bash
curl -X POST "http://localhost:8000/api/v1/upload" \
  -F "file=@input.xlsx" \
  -F "verification_date_column=Дата поверки" \
  -F "certificate_number_column=Номер свидетельства" \
  -F "sheet_name=Перечень"
```

## Формат входных и выходных данных
- Вход: Excel-файл с минимум двумя колонками:
  - номер свидетельства (`С-ДМБ/31-12-2021/148367347`, `С-ГЭШ/31-12-2023/311364910`, и т.п.);
  - дата поверки в одном из поддерживаемых форматов (`31.12.2023`, `2023-12-31`, `31/12/2023`).
  Неверные или пустые даты пропускаются с логированием.
  - **Рекомендуется** добавлять колонку «Действительна до» — сервис использует её для подсказки года следующей поверки и поиска актуальных записей.
- Выход: `output.xlsx` c расширенными колонками:
  `ID в Аршине`, `Организация-поверитель`, `Регистрационный номер типа СИ`,
`Наименование типа СИ`, `Обозначение типа СИ`, `Заводской номер`,
`Дата поверки`, `Действительна до`, `Номер свидетельства`,
`Статус обработки`, `Номер строки в исходном файле` (соответствует фактическому номеру строки, начиная со 2 строки после заголовка).

В консоль и в сводный отчёт выводится статистика обработки:
- обработано строк: X;
- успешно найдено: Y (из них обновлено Z, без изменений K);
- не найдено: N;
- ошибки формата сертификата: M.

## Таблица ошибок API
| Код | Сообщение                                    | Причина                                                  |
|-----|----------------------------------------------|----------------------------------------------------------|
| 400 | `Invalid request payload`                    | Некорректные параметры запроса                          |
| 409 | `Task not completed or failed`               | Запрошена выгрузка результата до завершения обработки    |
| 409 | `Task failed: ...`                           | Обработка завершилась ошибкой                            |
| 413 | `File size ... exceeds maximum allowed size` | Загружен слишком большой файл                           |
| 422 | `Unexpected file MIME type` и т.п.           | Файл не является допустимым Excel                       |
| 500 | `Upload failed`, `Results retrieval failed`  | Непредвиденная ошибка на сервере                         |
| 503 | `Rate limit exceeded` (middleware)           | Превышен лимит запросов с одного IP в минуту            |

## Полезные пути
- `src/services/` — ключевые сервисы (парсер Excel, клиент Аршина, обработчик данных, генератор отчётов).
- `tests/` — unit-, integration- и contract-тесты (минимальное покрытие 90%).
- `docker/` — Dockerfile и docker-compose для развёртывания.
- `docs/` — дополнительные материалы и шаблоны.

## Пример запуска обработки из Python
```python
import asyncio
from src.services.data_processor import DataProcessorService

async def run():
    processor = DataProcessorService()
    reports = await processor.process_excel_file("uploads/input.xlsx")
    print(f"Processed {len(reports)} records")
    await processor.close()

asyncio.run(run())
```

## Поддержка и развитие
Перед отправкой изменений запускайте форматирование и статический анализ:
```bash
uv run ruff check .
uv run black .
```
А затем тесты. При доработке учитывайте ограничения по частоте запросов в Аршин и необходимость аккумулировать статистику обработки для UI/интеграций.
